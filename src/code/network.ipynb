{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import img_to_array, Sequence\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import floor\n",
    "import random\n",
    "from datetime import datetime\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 pixel padding is added, this make the inputs 256x256 and 128x128 for a nice 2^n size\n",
    "\n",
    "HIGH_RES_IMAGE_SIZE = 2016\n",
    "LOW_RES_IMAGE_SIZE = 992\n",
    "\n",
    "HIGH_RES_CHUNK_SIZE = 252\n",
    "LOW_RES_CHUNK_SIZE = 126\n",
    "\n",
    "high_res_path = \"../input/high_res\"\n",
    "low_res_path = \"../input/low_res\"\n",
    "\n",
    "ADDED_PADDING = 2\n",
    "LOW_RES_PADDING = 1\n",
    "NETWORK_IMAGE_SIZE = HIGH_RES_CHUNK_SIZE + ADDED_PADDING * 2\n",
    "\n",
    "\n",
    "def prepare_images(high_res_filenames, low_res_paths):\n",
    "    high_res_tiles = []\n",
    "    for high_res_filename in high_res_filenames:\n",
    "        image = cv2.imread(f\"{high_res_path}/{high_res_filename}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.astype(\"float32\") / 255.0\n",
    "        height, width, _ = image.shape\n",
    "        assert height == width\n",
    "        assert height == HIGH_RES_IMAGE_SIZE\n",
    "        assert width == HIGH_RES_IMAGE_SIZE\n",
    "        np_image = img_to_array(image)\n",
    "        for y in range(0, height, HIGH_RES_CHUNK_SIZE):\n",
    "            for x in range(0, width, HIGH_RES_CHUNK_SIZE):\n",
    "                tile = np_image[\n",
    "                    y: y + HIGH_RES_CHUNK_SIZE, x: x + HIGH_RES_CHUNK_SIZE\n",
    "                ]\n",
    "                tile = cv2.copyMakeBorder(\n",
    "                    tile, ADDED_PADDING, ADDED_PADDING, ADDED_PADDING, ADDED_PADDING, cv2.BORDER_REFLECT)\n",
    "                high_res_tiles.append(tile)\n",
    "    low_res_tiles = []\n",
    "    for low_res_filename in low_res_paths:\n",
    "        image = cv2.imread(f\"{low_res_path}/{low_res_filename}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.astype(\"float32\") / 255.0\n",
    "        height, width, _ = image.shape\n",
    "        assert height == width\n",
    "        assert height == LOW_RES_IMAGE_SIZE\n",
    "        assert width == LOW_RES_IMAGE_SIZE\n",
    "        np_image = img_to_array(image)\n",
    "        for y in range(0, height, LOW_RES_CHUNK_SIZE):\n",
    "            for x in range(0, width, LOW_RES_CHUNK_SIZE):\n",
    "                tile = np_image[y: y + LOW_RES_CHUNK_SIZE,\n",
    "                                x: x + LOW_RES_CHUNK_SIZE]\n",
    "                tile = cv2.copyMakeBorder(\n",
    "                    tile, LOW_RES_PADDING, LOW_RES_PADDING, LOW_RES_PADDING, LOW_RES_PADDING, cv2.BORDER_REFLECT)\n",
    "                tile = cv2.resize(\n",
    "                    tile, (NETWORK_IMAGE_SIZE, NETWORK_IMAGE_SIZE))\n",
    "                low_res_tiles.append(img_to_array(tile))\n",
    "\n",
    "    return high_res_tiles, low_res_tiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_IMAGES = 0.2\n",
    "TEST_IMAGES = 0.1\n",
    "\n",
    "high_res_paths = os.listdir(high_res_path)\n",
    "low_res_paths = os.listdir(low_res_path)\n",
    "\n",
    "assert len(high_res_paths) == len(high_res_paths)\n",
    "\n",
    "data_size = len(high_res_paths)\n",
    "\n",
    "high_res_training = high_res_paths[\n",
    "    : -(floor(VALIDATION_IMAGES * data_size) + floor(TEST_IMAGES * data_size))\n",
    "]\n",
    "low_res_training = low_res_paths[\n",
    "    : -(floor(VALIDATION_IMAGES * data_size) + floor(TEST_IMAGES * data_size))\n",
    "]\n",
    "high_res_validation = high_res_paths[\n",
    "    -(floor(VALIDATION_IMAGES * data_size) + floor(TEST_IMAGES * data_size)): -floor(\n",
    "        TEST_IMAGES * data_size\n",
    "    )\n",
    "]\n",
    "low_res_validation = low_res_paths[\n",
    "    -(floor(VALIDATION_IMAGES * data_size) + floor(TEST_IMAGES * data_size)): -floor(\n",
    "        TEST_IMAGES * data_size\n",
    "    )\n",
    "]\n",
    "high_res_test = high_res_paths[-floor(TEST_IMAGES * data_size):]\n",
    "low_res_test = low_res_paths[-floor(TEST_IMAGES * data_size):]\n",
    "\n",
    "len(high_res_training), len(high_res_validation), len(high_res_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_paths, y_paths, items_per_image, pre_shape_size, batch_size):\n",
    "        self.x_paths, self.y_paths = x_paths, y_paths\n",
    "        self.pre_shape_size, self.batch_size = pre_shape_size, batch_size\n",
    "        self.items_per_image = items_per_image\n",
    "        self._reshape(0)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(\n",
    "            np.ceil(len(self.x_paths) * self.items_per_image /\n",
    "                    float(self.batch_size))\n",
    "        )\n",
    "\n",
    "    def shuffle(self):\n",
    "        seed = random.randint(0, 1024)\n",
    "        random.seed(seed)\n",
    "        random.shuffle(self.y_paths)\n",
    "        random.seed(seed)\n",
    "        random.shuffle(self.x_paths)\n",
    "\n",
    "    def _paths_index(self, index):\n",
    "        return floor(int(index * self.batch_size) / self.items_per_image)\n",
    "\n",
    "    def _reshape(self, new_index):\n",
    "        self.shape_index = new_index\n",
    "        self.paths_index = self._paths_index(new_index)\n",
    "\n",
    "        self.x_pre_shaped = None\n",
    "        self.y_pre_shaped = None\n",
    "\n",
    "        y_shuffled = self.y_paths[\n",
    "            self.paths_index: self.paths_index + self.pre_shape_size\n",
    "        ]\n",
    "        x_shuffled = self.x_paths[\n",
    "            self.paths_index: self.paths_index + self.pre_shape_size\n",
    "        ]\n",
    "\n",
    "        high_res_tiles, low_res_tiles = prepare_images(\n",
    "            y_shuffled,\n",
    "            x_shuffled,\n",
    "        )\n",
    "\n",
    "        new_len = len(high_res_tiles)\n",
    "\n",
    "        self.x_pre_shaped = np.reshape(\n",
    "            low_res_tiles,\n",
    "            (\n",
    "                new_len,\n",
    "                NETWORK_IMAGE_SIZE,\n",
    "                NETWORK_IMAGE_SIZE,\n",
    "                3,\n",
    "            ),\n",
    "        )\n",
    "        self.y_pre_shaped = np.reshape(\n",
    "            high_res_tiles,\n",
    "            (\n",
    "                new_len,\n",
    "                NETWORK_IMAGE_SIZE,\n",
    "                NETWORK_IMAGE_SIZE,\n",
    "                3,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, slice):\n",
    "            results_x, results_y = [], []\n",
    "            for image in range(index.start, index.stop):\n",
    "                x, y = self.__getitem__(image)\n",
    "                results_x.extend(x)\n",
    "                results_y.extend(y)\n",
    "            return results_x, results_y\n",
    "        else:\n",
    "            paths_index = self._paths_index(index)\n",
    "\n",
    "            if (\n",
    "                index < self.shape_index\n",
    "                or paths_index > self.paths_index + self.pre_shape_size - 1\n",
    "            ):\n",
    "                self._reshape(index)\n",
    "\n",
    "            index = index - self.shape_index\n",
    "\n",
    "            batch_x = self.x_pre_shaped[\n",
    "                index * self.batch_size: (index + 1) * self.batch_size\n",
    "            ]\n",
    "            batch_y = self.y_pre_shaped[\n",
    "                index * self.batch_size: (index + 1) * self.batch_size\n",
    "            ]\n",
    "            return batch_x, batch_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "PRE_SHAPE_SIZE = 16\n",
    "TILES_PER_IMAGE = (HIGH_RES_IMAGE_SIZE / HIGH_RES_CHUNK_SIZE) ** 2\n",
    "\n",
    "training_generator = DataGenerator(\n",
    "    low_res_training, high_res_training, TILES_PER_IMAGE, PRE_SHAPE_SIZE, BATCH_SIZE\n",
    ")\n",
    "validation_generator = DataGenerator(\n",
    "    low_res_validation,\n",
    "    high_res_validation,\n",
    "    TILES_PER_IMAGE,\n",
    "    PRE_SHAPE_SIZE,\n",
    "    BATCH_SIZE,\n",
    ")\n",
    "test_generator = DataGenerator(\n",
    "    low_res_test, high_res_test, TILES_PER_IMAGE, PRE_SHAPE_SIZE, 1\n",
    ")\n",
    "\n",
    "\n",
    "def regen_data():\n",
    "    training_generator.shuffle()\n",
    "    validation_generator.shuffle()\n",
    "    test_generator.shuffle()\n",
    "\n",
    "\n",
    "regen_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_img = tf.keras.layers.Input(\n",
    "        shape=(NETWORK_IMAGE_SIZE, NETWORK_IMAGE_SIZE, 3))\n",
    "\n",
    "    l1 = tf.keras.layers.Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(input_img)\n",
    "    l2 = tf.keras.layers.Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(l1)\n",
    "    l3 = tf.keras.layers.MaxPool2D(padding=\"same\")(l2)\n",
    "\n",
    "    l4 = tf.keras.layers.Conv2D(\n",
    "        128,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(l3)\n",
    "    l5 = tf.keras.layers.Conv2D(\n",
    "        128,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(l4)\n",
    "    l6 = tf.keras.layers.MaxPool2D(padding=\"same\")(l5)\n",
    "\n",
    "    l7 = tf.keras.layers.Conv2D(\n",
    "        256,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(l6)\n",
    "\n",
    "    l8 = tf.keras.layers.Conv2DTranspose(\n",
    "        256,\n",
    "        (3, 3),\n",
    "        strides=(2, 2),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(l7)\n",
    "    l9 = tf.keras.layers.Conv2D(\n",
    "        128,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(l8)\n",
    "    l10 = tf.keras.layers.Conv2D(\n",
    "        128,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(l9)\n",
    "\n",
    "    l11 = tf.keras.layers.add([l10, l5])\n",
    "\n",
    "    l12 = tf.keras.layers.Conv2DTranspose(\n",
    "        128,\n",
    "        (3, 3),\n",
    "        strides=(2, 2),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(l11)\n",
    "    l13 = tf.keras.layers.Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(l12)\n",
    "    l14 = tf.keras.layers.Conv2D(\n",
    "        64,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(l13)\n",
    "\n",
    "    l15 = tf.keras.layers.add([l14, l2])\n",
    "\n",
    "    decoded_image = tf.keras.layers.Conv2D(\n",
    "        3,\n",
    "        (3, 3),\n",
    "        padding=\"same\",\n",
    "        kernel_initializer=\"he_uniform\",\n",
    "        activation=\"relu\",\n",
    "        dtype='float32',\n",
    "        activity_regularizer=tf.keras.regularizers.l1(10e-10),\n",
    "    )(l15)\n",
    "\n",
    "    return tf.keras.models.Model(inputs=(input_img), outputs=decoded_image)\n",
    "\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    create_model(), show_shapes=True, show_layer_names=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Callbacks(keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        regen_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE loss model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_model = create_model()\n",
    "\n",
    "mse_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "for _ in range(3):\n",
    "    mse_model.fit(\n",
    "        training_generator,\n",
    "        shuffle=False,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[Callbacks()]\n",
    "    )\n",
    "\n",
    "    timestamp = int(datetime.timestamp(datetime.now()) * 1000)\n",
    "    mse_model.save(f'mse-checkpoint-{timestamp}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    mse_model.fit(\n",
    "        training_generator,\n",
    "        shuffle=False,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[Callbacks()]\n",
    "    )\n",
    "\n",
    "    timestamp = int(datetime.timestamp(datetime.now()) * 1000)\n",
    "    mse_model.save(f'mse-checkpoint-{timestamp}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_best = tf.keras.models.load_model(\n",
    "#     \"mse-checkpoint-1655412386260.h5\"\n",
    "# )\n",
    "\n",
    "mse_best = mse_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSIM loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSIMLoss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_model = create_model()\n",
    "\n",
    "ssim_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=SSIMLoss,\n",
    "    metrics=[\"acc\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    ssim_history = ssim_model.fit(\n",
    "        training_generator,\n",
    "        epochs=2,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[Callbacks()])\n",
    "\n",
    "    timestamp = int(datetime.timestamp(datetime.now()) * 1000)\n",
    "    ssim_model.save(f'ssim-checkpoint-{timestamp}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssim_best = tf.keras.models.load_model(\n",
    "#     \"ssim-checkpoint-1654698942576.h5\", custom_objects={\"SSIMLoss\": SSIMLoss, \"ssim_loss\": SSIMLoss}\n",
    "# )\n",
    "\n",
    "ssim_best = ssim_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lpipstf.lpips_tf import get_lpips, load_lpips\n",
    "\n",
    "graph_file = load_lpips()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_model = create_model()\n",
    "\n",
    "pl_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=get_lpips(graph_file),\n",
    "    metrics=[\"acc\"],\n",
    ")\n",
    "\n",
    "pl_history = pl_model.fit(\n",
    "    training_generator,\n",
    "    epochs=5,\n",
    "    validation_data=validation_generator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = int(datetime.timestamp(datetime.now()) * 1000)\n",
    "pl_model.save(f'pl-checkpoint-{timestamp}.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_history_2 = pl_model.fit(\n",
    "    training_generator,\n",
    "    epochs=2,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[Callbacks()],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(high, low, predicted):\n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"High Image\", color=\"green\", fontsize=20)\n",
    "    plt.imshow(high)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Low Image \", color=\"black\", fontsize=20)\n",
    "    plt.imshow(low)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Predicted Image \", color=\"Red\", fontsize=20)\n",
    "    plt.imshow(predicted)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_my_image(index, pictures, tilings, model):\n",
    "    (vertical_segments, horizontal_segments), res = tilings[index]\n",
    "    start_index = sum(v * h for (v, h), _ in tilings[:index])\n",
    "    end_index = start_index + vertical_segments * horizontal_segments\n",
    "\n",
    "    def join_images(tiles, local_tiling):\n",
    "        result = None\n",
    "        (h, v), resolutions = local_tiling\n",
    "\n",
    "        for h_i in range(h):\n",
    "            current_row = None\n",
    "\n",
    "            for v_i in range(v):\n",
    "                tile = tiles[v_i + h_i * v]\n",
    "                local_height, local_width = resolutions[v_i + h_i * v]\n",
    "                tile = tile[ADDED_PADDING:-ADDED_PADDING,\n",
    "                            ADDED_PADDING:-ADDED_PADDING]\n",
    "\n",
    "                tile = cv2.resize(tile, (local_width, local_height))\n",
    "                tile = cv2.copyMakeBorder(tile, 0, HIGH_RES_CHUNK_SIZE - local_height,\n",
    "                                          0, HIGH_RES_CHUNK_SIZE - local_width, cv2.BORDER_CONSTANT)\n",
    "                if current_row is None:\n",
    "                    current_row = np.array(tile)\n",
    "                else:\n",
    "                    current_row = np.concatenate((current_row, tile), axis=1)\n",
    "\n",
    "            if result is None:\n",
    "                result = current_row\n",
    "            else:\n",
    "                result = np.concatenate((result, current_row), axis=0)\n",
    "\n",
    "        total_height = sum([h for i, (h, _) in enumerate(\n",
    "            resolutions) if i % horizontal_segments == 0])\n",
    "        total_width = sum([v for i, (_, v) in enumerate(\n",
    "            resolutions) if i < vertical_segments])\n",
    "\n",
    "        current_height, current_width, _ = result.shape\n",
    "\n",
    "        if current_height != total_height:\n",
    "            result = result[:-(current_height - total_height), :]\n",
    "        if current_width != total_width:\n",
    "            result = result[:, :-(current_width - total_width)]\n",
    "\n",
    "        return result\n",
    "\n",
    "    highres, lowres = pictures[start_index:end_index]\n",
    "\n",
    "    reconstructed_high_res = join_images(\n",
    "        highres, tilings[index]\n",
    "    )\n",
    "    reconstructed_low_res = join_images(\n",
    "        lowres, tilings[index]\n",
    "    )\n",
    "    predicted_images = (\n",
    "        np.clip(\n",
    "            model.predict(\n",
    "                np.reshape(\n",
    "                    lowres,\n",
    "                    (\n",
    "                        end_index - start_index,\n",
    "                        NETWORK_IMAGE_SIZE,\n",
    "                        NETWORK_IMAGE_SIZE,\n",
    "                        3,\n",
    "                    ),\n",
    "                )\n",
    "            ),\n",
    "            0.0,\n",
    "            1.0,\n",
    "        )\n",
    "        .reshape(end_index - start_index, NETWORK_IMAGE_SIZE, NETWORK_IMAGE_SIZE, 3)\n",
    "    )\n",
    "    reconstructed_predicted = join_images(\n",
    "        predicted_images, tilings[index]\n",
    "    )\n",
    "\n",
    "    print(reconstructed_high_res.shape, reconstructed_low_res.shape,\n",
    "          reconstructed_predicted.shape)\n",
    "\n",
    "    return reconstructed_high_res, reconstructed_low_res, reconstructed_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(hr, lr, r, prefix=\"\"):\n",
    "    if hr is not None:\n",
    "        cv2.imwrite(\n",
    "            f\"../final-out/{prefix}-hr.png\",\n",
    "            cv2.cvtColor(\n",
    "                cv2.normalize(hr, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U),\n",
    "                cv2.COLOR_RGB2BGR,\n",
    "            ),\n",
    "        )\n",
    "    if lr is not None:\n",
    "        cv2.imwrite(\n",
    "            f\"../final-out/{prefix}-lr.png\",\n",
    "            cv2.cvtColor(\n",
    "                cv2.normalize(lr, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U),\n",
    "                cv2.COLOR_RGB2BGR,\n",
    "            ),\n",
    "        )\n",
    "    if r is not None:\n",
    "        cv2.imwrite(\n",
    "            f\"../final-out/{prefix}-r.png\",\n",
    "            cv2.cvtColor(\n",
    "                cv2.normalize(r, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U),\n",
    "                cv2.COLOR_RGB2BGR,\n",
    "            ),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [mse_best, ssim_best]\n",
    "\n",
    "\n",
    "test_results = []\n",
    "for model in models:\n",
    "    psnr = []\n",
    "    ssim = []\n",
    "    for i in range(100):\n",
    "        lr, hr, r = reconstruct_my_image(i, test_generator,\n",
    "                                         [((8, 8), [(252, 252) for _ in range(64)]) for _ in range(len(high_res_paths))], model)\n",
    "        psnr.append(peak_signal_noise_ratio(\n",
    "            hr, r))\n",
    "        ssim.append(structural_similarity(\n",
    "            hr, r, multichannel=True))\n",
    "\n",
    "    test_results.append((sum(psnr)/len(psnr), sum(ssim)/len(ssim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "\n",
    "def prepare_test_images(hr_files, lr_files, path):\n",
    "    tilings = []\n",
    "    high_res_tiles = []\n",
    "\n",
    "    print('Preparing high res...')\n",
    "    for high_res_filename in hr_files:\n",
    "        image = cv2.imread(f\"{path}/{high_res_filename}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.astype(\"float32\") / 255.0\n",
    "        height, width, _ = image.shape\n",
    "        np_image = img_to_array(image)\n",
    "        local_size = (ceil(height / HIGH_RES_CHUNK_SIZE),\n",
    "                      ceil(width / HIGH_RES_CHUNK_SIZE))\n",
    "        local_tilings = []\n",
    "        for y in range(0, height, HIGH_RES_CHUNK_SIZE):\n",
    "            for x in range(0, width, HIGH_RES_CHUNK_SIZE):\n",
    "                tile = np_image[\n",
    "                    y: y + HIGH_RES_CHUNK_SIZE, x: x + HIGH_RES_CHUNK_SIZE\n",
    "                ]\n",
    "                local_height, local_width, _ = tile.shape\n",
    "                local_tilings.append((local_height, local_width))\n",
    "                tile = cv2.resize(\n",
    "                    tile, (HIGH_RES_CHUNK_SIZE, HIGH_RES_CHUNK_SIZE))\n",
    "                tile = cv2.copyMakeBorder(\n",
    "                    tile, ADDED_PADDING, ADDED_PADDING, ADDED_PADDING, ADDED_PADDING, cv2.BORDER_REFLECT)\n",
    "                high_res_tiles.append(tile)\n",
    "        tilings.append((local_size, local_tilings))\n",
    "\n",
    "    print('Preparing low res...')\n",
    "    low_res_tiles = []\n",
    "    for low_res_filename in lr_files:\n",
    "        image = cv2.imread(f\"{path}/{low_res_filename}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = image.astype(\"float32\") / 255.0\n",
    "        height, width, _ = image.shape\n",
    "        np_image = img_to_array(image)\n",
    "        for y in range(0, height, LOW_RES_CHUNK_SIZE):\n",
    "            for x in range(0, width, LOW_RES_CHUNK_SIZE):\n",
    "                tile = np_image[y: y + LOW_RES_CHUNK_SIZE,\n",
    "                                x: x + LOW_RES_CHUNK_SIZE]\n",
    "                tile = cv2.resize(\n",
    "                    tile, (HIGH_RES_CHUNK_SIZE, HIGH_RES_CHUNK_SIZE))\n",
    "                tile = cv2.copyMakeBorder(\n",
    "                    tile, ADDED_PADDING, ADDED_PADDING, ADDED_PADDING, ADDED_PADDING, cv2.BORDER_REFLECT)\n",
    "                low_res_tiles.append(img_to_array(tile))\n",
    "\n",
    "    return high_res_tiles, low_res_tiles, tilings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_test_image(index, high_resolution_pictures, low_resolution_pictures, tilings, model):\n",
    "    (vertical_segments, horizontal_segments), res = tilings[index]\n",
    "    start_index = sum(v * h for (v, h), _ in tilings[:index])\n",
    "    end_index = start_index + vertical_segments * horizontal_segments\n",
    "\n",
    "    def join_images(tiles, local_tiling):\n",
    "        result = None\n",
    "        (h, v), resolutions = local_tiling\n",
    "\n",
    "        for h_i in range(h):\n",
    "            current_row = None\n",
    "\n",
    "            for v_i in range(v):\n",
    "                tile = tiles[v_i + h_i * v]\n",
    "                local_height, local_width = resolutions[v_i + h_i * v]\n",
    "                tile = tile[ADDED_PADDING:-ADDED_PADDING,\n",
    "                            ADDED_PADDING:-ADDED_PADDING]\n",
    "                tile = cv2.resize(tile, (local_width, local_height))\n",
    "                tile = cv2.copyMakeBorder(tile, 0, HIGH_RES_CHUNK_SIZE - local_height,\n",
    "                                          0, HIGH_RES_CHUNK_SIZE - local_width, cv2.BORDER_CONSTANT)\n",
    "                if current_row is None:\n",
    "                    current_row = np.array(tile)\n",
    "                else:\n",
    "                    current_row = np.concatenate((current_row, tile), axis=1)\n",
    "\n",
    "            if result is None:\n",
    "                result = current_row\n",
    "            else:\n",
    "                result = np.concatenate((result, current_row), axis=0)\n",
    "\n",
    "        total_height = sum([h for i, (h, _) in enumerate(\n",
    "            resolutions) if i % horizontal_segments == 0])\n",
    "        total_width = sum([v for i, (_, v) in enumerate(\n",
    "            resolutions) if i < vertical_segments])\n",
    "\n",
    "        current_height, current_width, _ = result.shape\n",
    "\n",
    "        if current_height != total_height:\n",
    "            result = result[:-(current_height - total_height), :]\n",
    "        if current_width != total_width:\n",
    "            result = result[:, :-(current_width - total_width)]\n",
    "\n",
    "        return result\n",
    "\n",
    "    reconstructed_high_res = join_images(\n",
    "        high_resolution_pictures[start_index:end_index], tilings[index]\n",
    "    )\n",
    "    reconstructed_low_res = join_images(\n",
    "        low_resolution_pictures[start_index:end_index], tilings[index]\n",
    "    )\n",
    "    predicted_images = (\n",
    "        np.clip(\n",
    "            model.predict(\n",
    "                np.reshape(\n",
    "                    low_resolution_pictures[start_index:end_index],\n",
    "                    (\n",
    "                        end_index - start_index,\n",
    "                        NETWORK_IMAGE_SIZE,\n",
    "                        NETWORK_IMAGE_SIZE,\n",
    "                        3,\n",
    "                    ),\n",
    "                )\n",
    "            ),\n",
    "            0.0,\n",
    "            1.0,\n",
    "        )\n",
    "        .reshape(end_index - start_index, NETWORK_IMAGE_SIZE, NETWORK_IMAGE_SIZE, 3)\n",
    "    )\n",
    "    reconstructed_predicted = join_images(\n",
    "        predicted_images, tilings[index]\n",
    "    )\n",
    "\n",
    "    return reconstructed_high_res, reconstructed_low_res, reconstructed_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# This expects files to have *_HR or *_LR endings to find the correct versions\n",
    "\n",
    "\n",
    "def create_image_pairs(image_paths):\n",
    "    matched_paths = [path for path in image_paths if re.match(\n",
    "        r'.*(HR|LR)\\.png', path)]\n",
    "    sorted_paths = sorted(matched_paths)\n",
    "    high_res = [path for index, path in enumerate(\n",
    "        sorted_paths) if index % 2 == 0]\n",
    "    low_res = [path for index, path in enumerate(\n",
    "        sorted_paths) if index % 2 == 1]\n",
    "\n",
    "    return high_res, low_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bsd100_path = '../dataset-tests/BSD100'\n",
    "set14_path = '../dataset-tests/Set14'\n",
    "set5_path = '../dataset-tests/Set5'\n",
    "\n",
    "bsd100_high, bsd100_low = create_image_pairs(os.listdir(bsd100_path))\n",
    "set14_high, set14_low = create_image_pairs(os.listdir(set14_path))\n",
    "set5_high, set5_low = create_image_pairs(os.listdir(set5_path))\n",
    "\n",
    "sets = [(len(bsd100_high), prepare_test_images(bsd100_high, bsd100_low, bsd100_path))\n",
    "        (len(set14_high), prepare_test_images(set14_high, set14_low, set14_path)),\n",
    "        (len(set5_high), prepare_test_images(set5_high, set5_low, set5_path))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_num = 2\n",
    "reconstructed_high_res, reconstructed_low_res, reconstructed_predicted = reconstruct_test_image(\n",
    "    image_num, sets[2][1][0], sets[2][1][1], sets[2][1][2], mse_best)\n",
    "\n",
    "plot_images(reconstructed_high_res, reconstructed_low_res,\n",
    "            reconstructed_predicted)\n",
    "save_images(None, None, reconstructed_predicted, f'set5-{image_num}-mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [mse_best, ssim_best]\n",
    "\n",
    "\n",
    "results = []\n",
    "for model in models:\n",
    "    model_results = []\n",
    "    for dataset in sets:\n",
    "        set_size, (set_high, set_low, set_tilings) = dataset\n",
    "        psnr = []\n",
    "        ssim = []\n",
    "        for i in range(set_size):\n",
    "            reconstructed_high_res, reconstructed_low_res, reconstructed_predicted = reconstruct_test_image(\n",
    "                i, set_high, set_low, set_tilings, model)\n",
    "            plot_images(reconstructed_high_res,\n",
    "                        reconstructed_low_res, reconstructed_predicted)\n",
    "            print(peak_signal_noise_ratio(\n",
    "                reconstructed_high_res, reconstructed_predicted), structural_similarity(\n",
    "                reconstructed_high_res, reconstructed_predicted, multichannel=True))\n",
    "            psnr.append(peak_signal_noise_ratio(\n",
    "                reconstructed_high_res, reconstructed_predicted))\n",
    "            ssim.append(structural_similarity(\n",
    "                reconstructed_high_res, reconstructed_predicted, multichannel=True))\n",
    "\n",
    "        model_results.append((sum(psnr)/len(psnr), sum(ssim)/len(ssim)))\n",
    "    results.append(model_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tfffff')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eac61cb407b2f0272e161e852daec37aa2a5a3b58303619318e22928352543ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
